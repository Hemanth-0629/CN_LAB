{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea132d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c940b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "# Define the paths to your image files\n",
    "image_dir = \"images\"\n",
    "\n",
    "# Initialize lists to store feature vectors and labels\n",
    "X = []  # Feature vectors\n",
    "y = []  # Labels (1 or 2)\n",
    "\n",
    "# Loop through the images and extract features\n",
    "for image_file in os.listdir(image_dir):\n",
    "    if image_file.startswith(\"poly\"):\n",
    "        image_path = os.path.join(image_dir, image_file)\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  # Load image in grayscale\n",
    "        if int(image_file[4]) <= 7:\n",
    "            label = 1  # Images poly1 to poly7 belong to class 1\n",
    "        else:\n",
    "            label = 2  # Images poly8 to poly14 belong to class 2\n",
    "        # Extract features (x1 and x2)\n",
    "        x1 = np.mean(image)\n",
    "        x2 = np.var(image)\n",
    "        X.append([x1, x2])\n",
    "        y.append(label)\n",
    "\n",
    "# Convert feature vectors and labels to numpy arrays\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3538a680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize weights and bias\n",
    "w = np.zeros(X.shape[1])\n",
    "b = 0\n",
    "\n",
    "# Define the perceptron function\n",
    "def perceptron(x):\n",
    "    return 1 if np.dot(w, x) + b > 0 else 2\n",
    "\n",
    "# Training the perceptron\n",
    "learning_rate = 0.01\n",
    "num_iterations = 1000\n",
    "for _ in range(num_iterations):\n",
    "    for i in range(len(X)):\n",
    "        prediction = perceptron(X[i])\n",
    "        if prediction != y[i]:\n",
    "            if prediction == 1:\n",
    "                w -= learning_rate * X[i]\n",
    "                b -= learning_rate\n",
    "            else:\n",
    "                w += learning_rate * X[i]\n",
    "                b += learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ac48b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define a function to plot the decision boundary\n",
    "def plot_decision_boundary(X, y, w, b):\n",
    "    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, 0.01), np.arange(x2_min, x2_max, 0.01))\n",
    "    Z = np.array([perceptron([x1, x2]) for x1, x2 in np.c_[xx1.ravel(), xx2.ravel()]])\n",
    "\n",
    "    Z = Z.reshape(xx1.shape)\n",
    "    plt.contourf(xx1, xx2, Z, alpha=0.4)\n",
    "    plt.scatter(X[y == 1][:, 0], X[y == 1][:, 1], label='Class 1', marker='o')\n",
    "    plt.scatter(X[y == 2][:, 0], X[y == 2][:, 1], label='Class 2', marker='x')\n",
    "    plt.xlabel('x1')\n",
    "    plt.ylabel('x2')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Plot the decision boundary\n",
    "plot_decision_boundary(X, y, w, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1db809a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define a function to plot the decision boundary\n",
    "def plot_decision_boundary(X, y, w, b):\n",
    "    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "\n",
    "    # Reduce the step size for creating the mesh grid\n",
    "    step = 0.1\n",
    "    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, step), np.arange(x2_min, x2_max, step))\n",
    "    \n",
    "    Z = np.array([perceptron([x1, x2]) for x1, x2 in np.c_[xx1.ravel(), xx2.ravel()]])\n",
    "\n",
    "    Z = Z.reshape(xx1.shape)\n",
    "    plt.contourf(xx1, xx2, Z, alpha=0.4)\n",
    "    plt.scatter(X[y == 1][:, 0], X[y == 1][:, 1], label='Class 1', marker='o')\n",
    "    plt.scatter(X[y == 2][:, 0], X[y == 2][:, 1], label='Class 2', marker='x')\n",
    "    plt.xlabel('x1')\n",
    "    plt.ylabel('x2')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Plot the decision boundary\n",
    "plot_decision_boundary(X, y, w, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e0249d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a meshgrid for the feature space with lower resolution\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1), np.arange(y_min, y_max, 0.1))  # Reduced resolution\n",
    "\n",
    "# Compute the decision boundary\n",
    "Z = np.array([perceptron([x1, x2]) for x1, x2 in np.c_[xx.ravel(), yy.ravel()]])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# Plot the decision boundary\n",
    "plt.contourf(xx, yy, Z, cmap=plt.cm.coolwarm, alpha=0.8)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.coolwarm)\n",
    "plt.xlabel('Feature 1 (x1)')\n",
    "plt.ylabel('Feature 2 (x2)')\n",
    "plt.title('Perceptron Decision Boundary')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdef159",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Define paths\n",
    "image_dir = \"C:\\\\Users\\\\vardh\\\\Desktop\\\\5th Sem\\\\PRML\\\\Lab10\\\\Images\"\n",
    "class1_images = range(1, 8)\n",
    "class2_images = range(8, 15)\n",
    "\n",
    "# Initialize lists to store feature vectors and labels\n",
    "X = []  # Feature vectors\n",
    "y = []  # Labels (1 or 2)\n",
    "\n",
    "# Loop through the images and extract features\n",
    "for i in class1_images:\n",
    "    image_path = os.path.join(image_dir, f\"poly{i}.png\")\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    x1 = np.mean(image)  # Calculate x1 (average pixel intensity)\n",
    "    x2 = np.var(image)   # Calculate x2 (variance of pixel intensity)\n",
    "    X.append([x1, x2])\n",
    "    y.append(1)  # Class 1\n",
    "\n",
    "for i in class2_images:\n",
    "    image_path = os.path.join(image_dir, f\"poly{i}.png\")\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    x1 = np.mean(image)  # Calculate x1 (average pixel intensity)\n",
    "    x2 = np.var(image)   # Calculate x2 (variance of pixel intensity)\n",
    "    X.append([x1, x2])\n",
    "    y.append(2)  # Class 2\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Shuffle the data\n",
    "X, y = shuffle(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e1ca6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the SVM parameters\n",
    "learning_rate = 0.01\n",
    "C = 1.0  # Regularization parameter\n",
    "\n",
    "# Initialize weights and bias\n",
    "w = np.zeros(X.shape[1])\n",
    "b = 0\n",
    "\n",
    "# Define the hinge loss function\n",
    "def hinge_loss(w, b, X, y):\n",
    "    loss = 1 - y * (np.dot(X, w) + b)\n",
    "    return max(0, loss)\n",
    "\n",
    "# Training the SVM using stochastic gradient descent\n",
    "num_iterations = 1000\n",
    "for _ in range(num_iterations):\n",
    "    for i in range(len(X)):\n",
    "        if y[i] * (np.dot(X[i], w) + b) >= 1:\n",
    "            w -= learning_rate * (2 * 1 / num_iterations * w)\n",
    "        else:\n",
    "            w -= learning_rate * (2 * 1 / num_iterations * w - np.dot(X[i], y[i]))\n",
    "            b -= learning_rate * y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ab661c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a meshgrid for the entire feature space\n",
    "xx, yy = np.meshgrid(np.linspace(X[:, 0].min() - 1, X[:, 0].max() + 1, 100),\n",
    "                     np.linspace(X[:, 1].min() - 1, X[:, 1].max() + 1, 100))\n",
    "\n",
    "# Predict the class labels for all points in the meshgrid\n",
    "Z = np.dot(np.c_[xx.ravel(), yy.ravel()], w) + b\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# Plot the decision boundary\n",
    "plt.contourf(xx, yy, Z, levels=[-1, 0, 1], colors=('blue', 'white', 'red'), alpha=0.4)\n",
    "plt.scatter(X[y == 1][:, 0], X[y == 1][:, 1], c='blue', label='Class 1')\n",
    "plt.scatter(X[y == 2][:, 0], X[y == 2][:, 1], c='red', label='Class 2')\n",
    "plt.xlabel('x1')\n",
    "plt.ylabel('x2')\n",
    "plt.title('SVM Decision Boundary')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
